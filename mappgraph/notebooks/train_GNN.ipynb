{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKQ1mORvDvSx"
      },
      "source": [
        "T5_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lcDoZ0o2Za3"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG9WNKzW8a8x",
        "outputId": "1f693f85-37e0-42f6-f604-fa10e1b5334e"
      },
      "outputs": [],
      "source": [
        "# install StellarGraph if running on Google Colab\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  %pip install -q stellargraph[demos]==1.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r1niN0z09sri"
      },
      "outputs": [],
      "source": [
        "# verify that we're using the correct version of StellarGraph for this notebook\n",
        "import stellargraph as sg\n",
        "\n",
        "try:\n",
        "    sg.utils.validate_notebook_version(\"1.2.1\")\n",
        "except AttributeError:\n",
        "    raise ValueError(\n",
        "        f\"This notebook requires StellarGraph version 1.2.1, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n",
        "    ) from None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AcQq7a-99v_n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from stellargraph import StellarGraph\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import stellargraph as sg\n",
        "from stellargraph.mapper import PaddedGraphGenerator\n",
        "from stellargraph.layer import DeepGraphCNN\n",
        "from stellargraph import datasets\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from utils import save_classification_report\n",
        "from IPython.display import display, HTML\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten,  BatchNormalization\n",
        "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tQfYJXo0JUeN"
      },
      "outputs": [],
      "source": [
        "# root_path = 'C:\\MAppGraph\\mappgraph\\data'\n",
        "# root_path = 'C:/MAppGraph/mappgraph/BOAdata'\n",
        "root_path = 'D:/Omri'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Y8LA582yMR"
      },
      "source": [
        "## Config setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2YHZAXTQJJvK"
      },
      "outputs": [],
      "source": [
        "N = 20\n",
        "t = 10\n",
        "k = 10  # the number of rows for the output tensor (k = 10, 20)\n",
        "T = 5\n",
        "overlap = 3 # note: overlap depends on T\n",
        "\n",
        "apps = ['diijam', 'baomoi', 'fptplay', 'iQIYI', 'bigo', 'myradio', 'spotify', 'nhaccuatui', 'soundcloud', 'sachnoiapp', \n",
        "        'phim247', 'popskid', 'truyenaudiosachnoiviet', 'vieon', 'voizfm', 'tunefm', 'wetv', 'zingmp3', 'truyenaudio', 'baohay24h',\n",
        "        'freefire', 'among_us', 'azar', 'comico', 'nimotv', 'mangatoon', 'medoctruyen', 'nhacvang', 'noveltoon', 'radiofm',\n",
        "        'vtvgo', 'tivi24h', 'tinder', 'tinmoi24h', 'tivi360', 'tiktok', 'linkedin', 'tiki', 'tinhte', 'lotus', 'tivi247',\n",
        "        'tivi_truyentranh_webtoon', 'tuoitre_online', 'vietnamworks', 'wallstreet_journal', 'cnn_news', 'bbc_news', 'twitter', \n",
        "        'weeboo', 'twitch', 'vnexpress', 'topcv', 'toc_chien', 'wesing', 'hago', 'google_meet', 'dubsmash', 'facebook','hahalolo', \n",
        "        'zalo', 'hello_yo', 'dan_tri', 'zoom', 'wikipedia', 'instagram', 'jobway', 'kaka', 'pinterest', 'quora', 'lazada', 'chess', \n",
        "        'cake', 'mobile_legend', 'co_tuong_online', 'ted', 'telegram', 'starmarker', 'skype', 'soha', 'tango', 'thanhnien', 'snapchat', \n",
        "        'tien_len', 'animal_restaurant', 'bida', 'cho_tot', 'messenger', 'netflix', 'nonolive', 'may', 'podcast_player', 'pubg', \n",
        "        'partying', 'kenh14', 'lienquan_mobile', 'likee_lite', 'reddit', 'sendo', 'shopee', 'the_guardian', 'ola_party']\n",
        "\n",
        "features = ['complete_max', 'complete_min', 'complete_mean', 'complete_mad', 'complete_std', 'complete_var', 'complete_skew',\n",
        "       'complete_kurt', 'complete_pkt_num', 'complete_10per', 'complete_20per', 'complete_30per', 'complete_40per', 'complete_50per', \n",
        "        'complete_60per', 'complete_70per', 'complete_80per', 'complete_90per', 'out_max', 'out_min', 'out_mean', 'out_mad', 'out_std',\n",
        "        'out_var', 'out_skew', 'out_kurt', 'out_pkt_num', 'out_10per', 'out_20per', 'out_30per', 'out_40per', 'out_50per', 'out_60per',\n",
        "        'out_70per', 'out_80per', 'out_90per', 'in_max', 'in_min', 'in_mean', 'in_mad', 'in_std', 'in_var', 'in_skew', 'in_kurt', \n",
        "        'in_pkt_num', 'in_10per', 'in_20per', 'in_30per', 'in_40per', 'in_50per', 'in_60per', 'in_70per', 'in_80per', 'in_90per', \n",
        "        'protocol', 'flows_num', 'flow_length_mean', 'flow_pkt_num_mean', 'flow_duration_mean', 'ip1', 'ip2', 'ip3', 'ip4'\n",
        "       ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JCENiV3-gyRf"
      },
      "outputs": [],
      "source": [
        "train_graphs_folder = os.path.join(root_path, '%d_%d/train_graphs/N%d/t%d'%(T, overlap, N, t))\n",
        "test_graphs_folder = os.path.join(root_path, '%d_%d/test_graphs/N%d/t%d'%(T, overlap, N, t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjW7cSVJ94-S"
      },
      "source": [
        "## Loading graphs for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7glSmi_xsjgK"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Load graphs for one app\n",
        "Input: app and folder that contains graphs of the app\n",
        "Output: List of graphs (StellarGraph objects) and List of labels\n",
        "'''\n",
        "def graphs_one_app(app, graphs_folder):\n",
        "  graphs = []\n",
        "\n",
        "  app_graph_folder = os.path.join(graphs_folder, app)\n",
        "  features_path = os.path.join(app_graph_folder, 'features.csv')\n",
        "  weights_path = os.path.join(app_graph_folder, 'weights.csv')\n",
        "\n",
        "  features_df = pd.read_csv(features_path, index_col=0)\n",
        "  weights_df = pd.read_csv(weights_path, index_col=0)\n",
        "\n",
        "  graph_num = features_df['graph_id'].iloc[-1]\n",
        "  # loop over all graphs of the app\n",
        "  for i in range(1, graph_num+1):\n",
        "    feature_df = features_df[features_df['graph_id'] == i]\n",
        "    feature_df = feature_df[['IP_port'] + features + ['graph_id']]\n",
        "    feature_df = feature_df.set_index('IP_port')\n",
        "    \n",
        "    weight_df = weights_df[weights_df['graph_id'] == i].reset_index(drop=True)\n",
        "\n",
        "    # drop graph_id column\n",
        "    feature_df = feature_df.drop(['graph_id'], axis=1)\n",
        "    weight_df = weight_df.drop(['graph_id'], axis=1)\n",
        "\n",
        "    if weight_df.shape[0] > 0:\n",
        "      graph = StellarGraph(feature_df, weight_df)\n",
        "      graphs.append(graph)\n",
        "\n",
        "  labels = [app]*graph_num\n",
        "    \n",
        "  return graphs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1kny4ma265qf"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Load all graphs\n",
        "Input: folder that contains graphs\n",
        "Output: List of graphs (StellarGraph objects), List of graph_labels (dummy values) and List of labels (names of app)\n",
        "'''\n",
        "def generate_graphs(graphs_folder):\n",
        "  # build a list of graphs and labels: note that only apply for more than 2 classes\n",
        "  li = []\n",
        "  labels = []\n",
        "  idx = 0\n",
        "\n",
        "  for app in apps:\n",
        "    idx += 1\n",
        "    print('Loading {} ... {}/{}'.format(app, idx, len(apps)))\n",
        "    \n",
        "    one_app_graphs, one_app_labels = graphs_one_app(app, graphs_folder)\n",
        "    li.extend(one_app_graphs)\n",
        "    labels.extend(one_app_labels)\n",
        "    \n",
        "\n",
        "  graph_labels = pd.get_dummies(labels)\n",
        "  graphs = li\n",
        "\n",
        "  print('...............................................................')\n",
        "\n",
        "  return graphs, graph_labels, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p667q9A7r44A"
      },
      "source": [
        "Load graphs from csv files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGabFHxmsAX9",
        "outputId": "980bacdd-a306-494e-88c8-1ca8c8d95695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading diijam ... 1/101\n",
            "Loading baomoi ... 2/101\n",
            "Loading fptplay ... 3/101\n",
            "Loading iQIYI ... 4/101\n",
            "Loading bigo ... 5/101\n",
            "Loading myradio ... 6/101\n",
            "Loading spotify ... 7/101\n",
            "Loading nhaccuatui ... 8/101\n",
            "Loading soundcloud ... 9/101\n",
            "Loading sachnoiapp ... 10/101\n",
            "Loading phim247 ... 11/101\n",
            "Loading popskid ... 12/101\n",
            "Loading truyenaudiosachnoiviet ... 13/101\n",
            "Loading vieon ... 14/101\n",
            "Loading voizfm ... 15/101\n",
            "Loading tunefm ... 16/101\n",
            "Loading wetv ... 17/101\n",
            "Loading zingmp3 ... 18/101\n",
            "Loading truyenaudio ... 19/101\n",
            "Loading baohay24h ... 20/101\n",
            "Loading freefire ... 21/101\n",
            "Loading among_us ... 22/101\n",
            "Loading azar ... 23/101\n",
            "Loading comico ... 24/101\n",
            "Loading nimotv ... 25/101\n",
            "Loading mangatoon ... 26/101\n",
            "Loading medoctruyen ... 27/101\n",
            "Loading nhacvang ... 28/101\n",
            "Loading noveltoon ... 29/101\n",
            "Loading radiofm ... 30/101\n",
            "Loading vtvgo ... 31/101\n",
            "Loading tivi24h ... 32/101\n",
            "Loading tinder ... 33/101\n",
            "Loading tinmoi24h ... 34/101\n",
            "Loading tivi360 ... 35/101\n",
            "Loading tiktok ... 36/101\n",
            "Loading linkedin ... 37/101\n",
            "Loading tiki ... 38/101\n",
            "Loading tinhte ... 39/101\n",
            "Loading lotus ... 40/101\n",
            "Loading tivi247 ... 41/101\n",
            "Loading tivi_truyentranh_webtoon ... 42/101\n",
            "Loading tuoitre_online ... 43/101\n",
            "Loading vietnamworks ... 44/101\n",
            "Loading wallstreet_journal ... 45/101\n",
            "Loading cnn_news ... 46/101\n",
            "Loading bbc_news ... 47/101\n",
            "Loading twitter ... 48/101\n",
            "Loading weeboo ... 49/101\n",
            "Loading twitch ... 50/101\n",
            "Loading vnexpress ... 51/101\n",
            "Loading topcv ... 52/101\n",
            "Loading toc_chien ... 53/101\n",
            "Loading wesing ... 54/101\n",
            "Loading hago ... 55/101\n",
            "Loading google_meet ... 56/101\n",
            "Loading dubsmash ... 57/101\n",
            "Loading facebook ... 58/101\n",
            "Loading hahalolo ... 59/101\n",
            "Loading zalo ... 60/101\n",
            "Loading hello_yo ... 61/101\n",
            "Loading dan_tri ... 62/101\n",
            "Loading zoom ... 63/101\n",
            "Loading wikipedia ... 64/101\n",
            "Loading instagram ... 65/101\n",
            "Loading jobway ... 66/101\n",
            "Loading kaka ... 67/101\n",
            "Loading pinterest ... 68/101\n",
            "Loading quora ... 69/101\n",
            "Loading lazada ... 70/101\n",
            "Loading chess ... 71/101\n",
            "Loading cake ... 72/101\n",
            "Loading mobile_legend ... 73/101\n",
            "Loading co_tuong_online ... 74/101\n",
            "Loading ted ... 75/101\n",
            "Loading telegram ... 76/101\n",
            "Loading starmarker ... 77/101\n",
            "Loading skype ... 78/101\n",
            "Loading soha ... 79/101\n",
            "Loading tango ... 80/101\n",
            "Loading thanhnien ... 81/101\n",
            "Loading snapchat ... 82/101\n",
            "Loading tien_len ... 83/101\n",
            "Loading animal_restaurant ... 84/101\n",
            "Loading bida ... 85/101\n",
            "Loading cho_tot ... 86/101\n",
            "Loading messenger ... 87/101\n",
            "Loading netflix ... 88/101\n",
            "Loading nonolive ... 89/101\n",
            "Loading may ... 90/101\n",
            "Loading podcast_player ... 91/101\n",
            "Loading pubg ... 92/101\n",
            "Loading partying ... 93/101\n",
            "Loading kenh14 ... 94/101\n",
            "Loading lienquan_mobile ... 95/101\n",
            "Loading likee_lite ... 96/101\n",
            "Loading reddit ... 97/101\n",
            "Loading sendo ... 98/101\n",
            "Loading shopee ... 99/101\n",
            "Loading the_guardian ... 100/101\n",
            "Loading ola_party ... 101/101\n",
            "...............................................................\n",
            "Loading diijam ... 1/101\n",
            "Loading baomoi ... 2/101\n",
            "Loading fptplay ... 3/101\n",
            "Loading iQIYI ... 4/101\n",
            "Loading bigo ... 5/101\n",
            "Loading myradio ... 6/101\n",
            "Loading spotify ... 7/101\n",
            "Loading nhaccuatui ... 8/101\n",
            "Loading soundcloud ... 9/101\n",
            "Loading sachnoiapp ... 10/101\n",
            "Loading phim247 ... 11/101\n",
            "Loading popskid ... 12/101\n",
            "Loading truyenaudiosachnoiviet ... 13/101\n",
            "Loading vieon ... 14/101\n",
            "Loading voizfm ... 15/101\n",
            "Loading tunefm ... 16/101\n",
            "Loading wetv ... 17/101\n",
            "Loading zingmp3 ... 18/101\n",
            "Loading truyenaudio ... 19/101\n",
            "Loading baohay24h ... 20/101\n",
            "Loading freefire ... 21/101\n",
            "Loading among_us ... 22/101\n",
            "Loading azar ... 23/101\n",
            "Loading comico ... 24/101\n",
            "Loading nimotv ... 25/101\n",
            "Loading mangatoon ... 26/101\n",
            "Loading medoctruyen ... 27/101\n",
            "Loading nhacvang ... 28/101\n",
            "Loading noveltoon ... 29/101\n",
            "Loading radiofm ... 30/101\n",
            "Loading vtvgo ... 31/101\n",
            "Loading tivi24h ... 32/101\n",
            "Loading tinder ... 33/101\n",
            "Loading tinmoi24h ... 34/101\n",
            "Loading tivi360 ... 35/101\n",
            "Loading tiktok ... 36/101\n",
            "Loading linkedin ... 37/101\n",
            "Loading tiki ... 38/101\n",
            "Loading tinhte ... 39/101\n",
            "Loading lotus ... 40/101\n",
            "Loading tivi247 ... 41/101\n",
            "Loading tivi_truyentranh_webtoon ... 42/101\n",
            "Loading tuoitre_online ... 43/101\n",
            "Loading vietnamworks ... 44/101\n",
            "Loading wallstreet_journal ... 45/101\n",
            "Loading cnn_news ... 46/101\n",
            "Loading bbc_news ... 47/101\n",
            "Loading twitter ... 48/101\n",
            "Loading weeboo ... 49/101\n",
            "Loading twitch ... 50/101\n",
            "Loading vnexpress ... 51/101\n",
            "Loading topcv ... 52/101\n",
            "Loading toc_chien ... 53/101\n",
            "Loading wesing ... 54/101\n",
            "Loading hago ... 55/101\n",
            "Loading google_meet ... 56/101\n",
            "Loading dubsmash ... 57/101\n",
            "Loading facebook ... 58/101\n",
            "Loading hahalolo ... 59/101\n",
            "Loading zalo ... 60/101\n",
            "Loading hello_yo ... 61/101\n",
            "Loading dan_tri ... 62/101\n",
            "Loading zoom ... 63/101\n",
            "Loading wikipedia ... 64/101\n",
            "Loading instagram ... 65/101\n",
            "Loading jobway ... 66/101\n",
            "Loading kaka ... 67/101\n",
            "Loading pinterest ... 68/101\n",
            "Loading quora ... 69/101\n",
            "Loading lazada ... 70/101\n",
            "Loading chess ... 71/101\n",
            "Loading cake ... 72/101\n",
            "Loading mobile_legend ... 73/101\n",
            "Loading co_tuong_online ... 74/101\n",
            "Loading ted ... 75/101\n",
            "Loading telegram ... 76/101\n",
            "Loading starmarker ... 77/101\n",
            "Loading skype ... 78/101\n",
            "Loading soha ... 79/101\n",
            "Loading tango ... 80/101\n",
            "Loading thanhnien ... 81/101\n",
            "Loading snapchat ... 82/101\n",
            "Loading tien_len ... 83/101\n",
            "Loading animal_restaurant ... 84/101\n",
            "Loading bida ... 85/101\n",
            "Loading cho_tot ... 86/101\n",
            "Loading messenger ... 87/101\n",
            "Loading netflix ... 88/101\n",
            "Loading nonolive ... 89/101\n",
            "Loading may ... 90/101\n",
            "Loading podcast_player ... 91/101\n",
            "Loading pubg ... 92/101\n",
            "Loading partying ... 93/101\n",
            "Loading kenh14 ... 94/101\n",
            "Loading lienquan_mobile ... 95/101\n",
            "Loading likee_lite ... 96/101\n",
            "Loading reddit ... 97/101\n",
            "Loading sendo ... 98/101\n",
            "Loading shopee ... 99/101\n",
            "Loading the_guardian ... 100/101\n",
            "Loading ola_party ... 101/101\n",
            "...............................................................\n"
          ]
        }
      ],
      "source": [
        "train_graphs, train_graph_labels, _ = generate_graphs(train_graphs_folder)\n",
        "test_graphs, test_graph_labels, _ = generate_graphs(test_graphs_folder)\n",
        "train_size = len(train_graphs)\n",
        "\n",
        "graphs = train_graphs + test_graphs\n",
        "graph_labels = train_graph_labels.append(test_graph_labels, ignore_index=True)\n",
        "\n",
        "test_graph_labels = graph_labels[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iyDhfLE9MIpU"
      },
      "outputs": [],
      "source": [
        "generator = PaddedGraphGenerator(graphs=graphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXBLvOISbXz"
      },
      "source": [
        "## Build GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiKbAm3kMjay",
        "outputId": "3e4a5acb-d8bd-46ad-dfdc-9bb54e509309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\עומרי\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        }
      ],
      "source": [
        "layer_sizes = [1024, 1024, 1024, 512]\n",
        "\n",
        "dgcnn_model = DeepGraphCNN(\n",
        "    layer_sizes=layer_sizes,\n",
        "    activations=[\"tanh\", \"tanh\", \"tanh\", \"tanh\"],\n",
        "    k=k,\n",
        "    bias=False,\n",
        "    generator=generator,\n",
        ")\n",
        "x_inp, x_out = dgcnn_model.in_out_tensors()\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "x_out = Conv1D(filters=256, kernel_size=sum(layer_sizes), strides=sum(layer_sizes))(x_out)\n",
        "x_out = MaxPool1D(pool_size=2)(x_out)\n",
        "\n",
        "x_out = Conv1D(filters=512, kernel_size=5, strides=1)(x_out)\n",
        "\n",
        "x_out = Flatten()(x_out)\n",
        "\n",
        "x_out = Dense(units=1024, activation=\"relu\")(x_out)\n",
        "x_out = Dropout(rate=0.25)(x_out)\n",
        "\n",
        "predictions = Dense(units=len(apps), activation=\"softmax\")(x_out)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "model = Model(inputs=x_inp, outputs=predictions)\n",
        "\n",
        "# using exponentialDecay to decrease the learning rate after 10 epochs\n",
        "# lr =  initial_lr * decay_rate ^ (step / decay_steps)\n",
        "batch_size = 256\n",
        "decay_epoch = 20\n",
        "\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0001,\n",
        "    decay_steps=(train_size//batch_size)*decay_epoch,\n",
        "    decay_rate=0.9)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer, loss=categorical_crossentropy, metrics=[\"acc\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7DG1_5EWa6r",
        "outputId": "1e31547d-7e85-4c38-c8de-c04b3e8e284d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 63)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 63)     0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None, None)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "graph_convolution (GraphConvolu (None, None, 1024)   64512       dropout[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 1024)   0           graph_convolution[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "graph_convolution_1 (GraphConvo (None, None, 1024)   1048576     dropout_1[0][0]                  \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, 1024)   0           graph_convolution_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "graph_convolution_2 (GraphConvo (None, None, 1024)   1048576     dropout_2[0][0]                  \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, None, 1024)   0           graph_convolution_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "graph_convolution_3 (GraphConvo (None, None, 512)    524288      dropout_3[0][0]                  \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (None, None, 3584)   0           graph_convolution[0][0]          \n",
            "                                                                 graph_convolution_1[0][0]        \n",
            "                                                                 graph_convolution_2[0][0]        \n",
            "                                                                 graph_convolution_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sort_pooling (SortPooling)      (None, 35840, 1)     0           tf.concat[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 10, 256)      917760      sort_pooling[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 5, 256)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 1, 512)       655872      max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 512)          0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         525312      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 101)          103525      dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,888,421\n",
            "Trainable params: 4,888,421\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L1Ij6mb6MnDR"
      },
      "outputs": [],
      "source": [
        "gen = PaddedGraphGenerator(graphs=graphs)\n",
        "\n",
        "train_gen = gen.flow(\n",
        "    list(train_graph_labels.index - 1),\n",
        "    targets=train_graph_labels.values,\n",
        "    batch_size=256,\n",
        "    symmetric_normalization=False,\n",
        ")\n",
        "\n",
        "test_gen = gen.flow(\n",
        "    list(test_graph_labels.index - 1),\n",
        "    targets=test_graph_labels.values,\n",
        "    batch_size=256,\n",
        "    symmetric_normalization=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0epzLQdnBigR"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWLELgWLMyTz",
        "outputId": "e9033bad-08e2-4694-d05d-46f0bdf74fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "259/259 [==============================] - 421s 2s/step - loss: 4.5030 - acc: 0.0264 - val_loss: 3.7983 - val_acc: 0.1601\n",
            "Epoch 2/150\n",
            "259/259 [==============================] - 420s 2s/step - loss: 3.6651 - acc: 0.1333 - val_loss: 2.9257 - val_acc: 0.2894\n",
            "Epoch 3/150\n",
            "259/259 [==============================] - 421s 2s/step - loss: 2.9821 - acc: 0.2501 - val_loss: 2.4204 - val_acc: 0.4066\n",
            "Epoch 4/150\n",
            "259/259 [==============================] - 524s 2s/step - loss: 2.6146 - acc: 0.3312 - val_loss: 2.1963 - val_acc: 0.4425\n",
            "Epoch 5/150\n",
            "259/259 [==============================] - 459s 2s/step - loss: 2.3401 - acc: 0.3869 - val_loss: 2.0281 - val_acc: 0.4786\n",
            "Epoch 6/150\n",
            "226/259 [=========================>....] - ETA: 1:00 - loss: 2.1371 - acc: 0.4327"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5032\\1076149971.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# epochs = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m )\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class CustomSaver(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % 10 == 0 & epoch > 0:  # or save after some epoch, each k-th epoch etc.\n",
        "            self.model.save(os.path.join(models_folder, \"model_{}.hd5\".format(epoch)))\n",
        "# create and use callback:\n",
        "saver = CustomSaver()\n",
        "\n",
        "epochs = 150\n",
        "# epochs = 1\n",
        "history = model.fit(\n",
        "    train_gen, callbacks=[saver], epochs=epochs, verbose=1, validation_data=test_gen, shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "-6TF6ideNQrE",
        "outputId": "2585f972-2fe0-4793-bed5-b66fd2eab32b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'sg' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4880\\2353548318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'sg' is not defined"
          ]
        }
      ],
      "source": [
        "sg.utils.plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYiAVVb2BnZ3"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAogToc6-7Pt",
        "outputId": "67ba6fac-ebca-47ae-a561-a3f4d1689204"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4880\\3794454595.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use the model to predict on testing data and get predicted labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# use the model to predict on testing data and get predicted labels\n",
        "pred_prob = model.predict(test_gen)\n",
        "pred_labels = np.argmax(pred_prob, axis=-1) \n",
        "pred_labels = [str(x+1) for x in list(pred_labels)]\n",
        "\n",
        "# get the true labels of the testing data\n",
        "test_labels = np.argmax(test_graph_labels.values, axis=-1)\n",
        "test_labels = [str(x+1) for x in list(test_labels)]\n",
        "\n",
        "# show the result as classification report\n",
        "print(classification_report(test_labels, pred_labels, target_names=apps, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'confusion_matrix' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4880\\2002859015.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m '''\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m heatmap = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g', \n",
            "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
          ]
        }
      ],
      "source": [
        "# Test Model/Predict\n",
        "'''\n",
        "We let the model predict some samples and then show on a confusion matrix plot the results.\n",
        "All results such as classification report, confusion matrix and plot, are saved into a \n",
        "time stamped directory under reports/ \n",
        "'''\n",
        "\n",
        "cf_matrix = confusion_matrix(test_labels, pred_labels)\n",
        "print(cf_matrix)\n",
        "heatmap = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g', \n",
        "                      xticklabels=np.unique(test_labels), \n",
        "                      yticklabels=np.unique(test_labels)) \n",
        "\n",
        "print(classification_report(test_labels, pred_labels, target_names=apps))\n",
        "\n",
        "\n",
        "# Save results in file\n",
        "save_classification_report(\n",
        "    classification_report(test_labels, pred_labels),\n",
        "    cf_matrix,\n",
        "    heatmap,\n",
        "    'C:\\MAppGraph\\mappgraph\\data'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLjP43YH-uOY"
      },
      "source": [
        "-------------------------------------------------------------"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_GNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
